{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Cascade RCNN\n",
    "\n",
    "In this notebook, we will train Cascade RCNN ResNet 101 model. We have created the config for this model which is present in src folder with filename - training_crcnn_5k_r101.py.\n",
    "Some notable points that we used in the config are as follows:\n",
    "1. We are using Cascade RCNN - ResNet 101 model.\n",
    "2. Number of training epochs is set to 24 with learning rate decreasing by a factor of 10 at epoch 12 and 22.\n",
    "3. Image Scale is set to (5000,5000).\n",
    "4. Max bounding box predictions per image is set to 400.\n",
    "5. 90% of data is used for training. Rest 10% is used for validation. For dividing the data into train and validation set, we took 10% of files randomly from each stain for validation set.\n",
    "\n",
    "**We do NOT need a GPU for this notebook**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3           # For interacting with S3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys             # Python system library needed to load custom functions\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Imports to run Sagemaker training jobs\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.session import Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../src')  # Add the source directory to the PYTHONPATH. This allows to import local functions and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n"
     ]
    }
   ],
   "source": [
    "from config import DEFAULT_BUCKET, DEFAULT_REGION  # The name of the S3 bucket that contains the training data\n",
    "from detection_util import create_predictions\n",
    "from gdsc_util import download_and_extract_model, set_up_logging, extract_hyperparams, PROJECT_DIR\n",
    "from training_crcnn_5k_r101 import load_config\n",
    "from gdsc_util import load_sections_df\n",
    "from PredictionEvaluator import PredictionEvaluator\n",
    "\n",
    "set_up_logging()  # Sets up logging to console and .log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = str(PROJECT_DIR / 'data')\n",
    "cfg, base_file = load_config(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'faster_rcnn_r101_caffe_fpn_mstrain_3x_coco_20210526_095742-a7ae426d.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "opencv_num_threads = 0\n",
      "mp_start_method = 'fork'\n",
      "auto_scale_lr = dict(enable=True, base_batch_size=2)\n",
      "dataset_type = 'OnchoDataset'\n",
      "data_root = '/home/sagemaker-user/gdsc5-tutorials-public/data'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=(5000, 5000),\n",
      "        multiscale_mode='value',\n",
      "        keep_ratio=True),\n",
      "    dict(\n",
      "        type='RandomCrop',\n",
      "        crop_size=(0.3, 0.3),\n",
      "        crop_type='relative',\n",
      "        allow_negative_crop=True),\n",
      "    dict(\n",
      "        type='RandomFlip',\n",
      "        flip_ratio=[0.5, 0.5],\n",
      "        direction=['horizontal', 'vertical']),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[103.53, 116.28, 123.675],\n",
      "        std=[1.0, 1.0, 1.0],\n",
      "        to_rgb=False),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(5000, 5000),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=2,\n",
      "    workers_per_gpu=1,\n",
      "    train=dict(\n",
      "        type='RepeatDataset',\n",
      "        times=2,\n",
      "        dataset=dict(\n",
      "            type='OnchoDataset',\n",
      "            ann_file='gdsc_train_dataset.csv',\n",
      "            img_prefix='jpgs/',\n",
      "            pipeline=[\n",
      "                dict(type='LoadImageFromFile'),\n",
      "                dict(type='LoadAnnotations', with_bbox=True),\n",
      "                dict(\n",
      "                    type='Resize',\n",
      "                    img_scale=(5000, 5000),\n",
      "                    multiscale_mode='value',\n",
      "                    keep_ratio=True),\n",
      "                dict(\n",
      "                    type='RandomCrop',\n",
      "                    crop_size=(0.3, 0.3),\n",
      "                    crop_type='relative',\n",
      "                    allow_negative_crop=True),\n",
      "                dict(\n",
      "                    type='RandomFlip',\n",
      "                    flip_ratio=[0.5, 0.5],\n",
      "                    direction=['horizontal', 'vertical']),\n",
      "                dict(\n",
      "                    type='Normalize',\n",
      "                    mean=[103.53, 116.28, 123.675],\n",
      "                    std=[1.0, 1.0, 1.0],\n",
      "                    to_rgb=False),\n",
      "                dict(type='Pad', size_divisor=32),\n",
      "                dict(type='DefaultFormatBundle'),\n",
      "                dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "            ],\n",
      "            data_root='/home/sagemaker-user/gdsc5-tutorials-public/data')),\n",
      "    val=dict(\n",
      "        type='OnchoDataset',\n",
      "        ann_file='gdsc_val_dataset.csv',\n",
      "        img_prefix='jpgs/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(5000, 5000),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/home/sagemaker-user/gdsc5-tutorials-public/data'),\n",
      "    test=dict(\n",
      "        type='OnchoDataset',\n",
      "        ann_file='gdsc_val_dataset.csv',\n",
      "        img_prefix='jpgs/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(5000, 5000),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        data_root='/home/sagemaker-user/gdsc5-tutorials-public/data'))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(type='SGD', lr=0.0025, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[12, 22])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=24)\n",
      "model = dict(\n",
      "    type='FasterRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=False),\n",
      "        norm_eval=True,\n",
      "        style='caffe',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='open-mmlab://detectron2/resnet101_caffe')),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='StandardRoIHead',\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=dict(\n",
      "            type='Shared2FCBBoxHead',\n",
      "            in_channels=256,\n",
      "            fc_out_channels=1024,\n",
      "            roi_feat_size=7,\n",
      "            num_classes=1,\n",
      "            bbox_coder=dict(\n",
      "                type='DeltaXYWHBBoxCoder',\n",
      "                target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "            reg_class_agnostic=False,\n",
      "            loss_cls=dict(\n",
      "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
      "            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=-1,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.5,\n",
      "                neg_iou_thr=0.5,\n",
      "                min_pos_iou=0.5,\n",
      "                match_low_quality=False,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=512,\n",
      "                pos_fraction=0.25,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=True),\n",
      "            pos_weight=-1,\n",
      "            debug=False)),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=400)))\n",
      "work_dir = '/home/sagemaker-user/gdsc5-tutorials-public/data/tutorial_exps/'\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "device = 'cuda'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a sagemaker training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-20 08:53:07,588 - sagemaker.image_uris - INFO - Defaulting to the only supported framework/algorithm version: latest.\n",
      "2022-07-20 08:53:07,606 - sagemaker.image_uris - INFO - Ignoring unnecessary instance type: None.\n",
      "2022-07-20 08:53:47,906 - sagemaker - INFO - Creating training-job with name: training-5k-r101-2022-07-20-08-53-07-587\n"
     ]
    }
   ],
   "source": [
    "entry_point = 'training_crcnn_5k_r101.py'\n",
    "exp_name = entry_point.split('.')[0].replace('_', '-')  # AWS does not allow . and _ as experiment names\n",
    "\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "role = get_execution_role()\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=DEFAULT_REGION)\n",
    "sess = Session(sagemaker_client=sm_client)\n",
    "s3_output_location = f\"s3://{sess.default_bucket()}/{exp_name}\"\n",
    "input_channels = {\"train\": f\"s3://{DEFAULT_BUCKET}\"}\n",
    "\n",
    "hyperparameters = extract_hyperparams(entry_point) # custom function to parse the training script and extract config\n",
    "hyperparameters['base_file'] = base_file\n",
    "\n",
    "metrics = [\n",
    "    {\"Name\": \"train:loss_rpn_cls\", \"Regex\": \"loss_rpn_cls: ([0-9\\.]+)\"},\n",
    "    {\"Name\": \"train:loss_rpn_bbox\", \"Regex\": \"loss_rpn_bbox: ([0-9\\.]+)\"},\n",
    "    {\"Name\": \"train:loss_cls\", \"Regex\": \"loss_cls: ([0-9\\.]+)\"},\n",
    "    {\"Name\": \"train:loss_bbox\", \"Regex\": \"loss_bbox: ([0-9\\.]+)\"},\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \"loss: ([0-9\\.]+)\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \"acc: ([0-9\\.]+)\"},\n",
    "    {\"Name\": \"train:epoch\", \"Regex\": \"Epoch (\\[[0-9\\.]+\\])\"},\n",
    "    {\"Name\": \"val:epoch\", \"Regex\": \"Epoch\\(val\\) (\\[[0-9]+\\])\"},\n",
    "    {\"Name\": \"val:mAP\", \"Regex\": \"mAP: ([0-9\\.]+)\"},\n",
    "]\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=entry_point,             # This function will be called by the training job\n",
    "    source_dir=\"../src\",                 # All code in this folder will be copied over\n",
    "    image_uri=f\"954362353459.dkr.ecr.{DEFAULT_REGION}.amazonaws.com/sm-training-custom:torch-1.8.1-cu111-noGPL\",\n",
    "    role=role,\n",
    "    output_path=s3_output_location,\n",
    "    container_log_level=20,             # 10=debug, 20=info\n",
    "    base_job_name=exp_name,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.g4dn.xlarge\",     # a GPU instance\n",
    "    volume_size=45,\n",
    "    metric_definitions=metrics,\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "estimator.fit(\n",
    "    input_channels,\n",
    "    wait=False,           # Whether or not the notebook should wait for the job to finish. By setting it to False we can continue working while the job runs on another machine.\n",
    ")\n",
    "\n",
    "# save the name of the experiment to the filesystem so that we can use it later\n",
    "experiment_name = estimator._hyperparameters[\"sagemaker_job_name\"]\n",
    "\n",
    "with open(f'{PROJECT_DIR}/experiment_crcnn_5k_r101_epoch_24.txt', 'w+') as f:\n",
    "    f.write(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the model and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the experiment name from the filesystem\n",
    "with open(f'{PROJECT_DIR}/experiment_crcnn_5k_r101_epoch_24.txt', 'r') as f:\n",
    "    experiment_name = f.read()\n",
    "\n",
    "model_location = f'{s3_output_location}/{experiment_name}/output/model.tar.gz'\n",
    "local_model_dir = download_and_extract_model(model_uri=model_location, local_dir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "python3 (gdsc5-smstudio-custom/1)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:914063116219:image-version/gdsc5-smstudio-custom/1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
